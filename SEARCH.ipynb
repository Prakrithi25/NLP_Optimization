{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b4031d-1673-428b-ae28-405895e7c97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: intel-extension-for-pytorch==2.2 in ./.local/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: psutil in /srv/jupyter/python-venv/lib/python3.11/site-packages (from intel-extension-for-pytorch==2.2) (5.9.5)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.11/site-packages (from intel-extension-for-pytorch==2.2) (2.2.3)\n",
      "Requirement already satisfied: packaging in /srv/jupyter/python-venv/lib/python3.11/site-packages (from intel-extension-for-pytorch==2.2) (23.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/srv/jupyter/python-venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.35.2 in ./.local/lib/python3.10/site-packages (4.35.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers==4.35.2) (2.2.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.local/lib/python3.10/site-packages (from transformers==4.35.2) (0.29.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from transformers==4.35.2) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers==4.35.2) (2024.11.6)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from transformers==4.35.2) (3.17.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.local/lib/python3.10/site-packages (from transformers==4.35.2) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.local/lib/python3.10/site-packages (from transformers==4.35.2) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers==4.35.2) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers==4.35.2) (2.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers==4.35.2) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2025.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==2.2.0 in ./.local/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /srv/jupyter/python-venv/lib/python3.11/site-packages (from torch==2.2.0) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /srv/jupyter/python-venv/lib/python3.11/site-packages (from torch==2.2.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in ./.local/lib/python3.11/site-packages (from torch==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /srv/jupyter/python-venv/lib/python3.11/site-packages (from jinja2->torch==2.2.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.11/site-packages (from sympy->torch==2.2.0) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/srv/jupyter/python-venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install intel-extension-for-pytorch==2.2\n",
    "!pip install transformers==4.35.2\n",
    "%pip install torch==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f167834-d8c0-4694-8d07-e5dceea920e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/srv/jupyter/python-venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/srv/jupyter/python-venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/srv/jupyter/python-venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install intel-extension-for-pytorch==2.2 --no-warn-script-location > /dev/null\n",
    "!{sys.executable} -m pip install transformers==4.35.2 --no-warn-script-location > /dev/null\n",
    "!{sys.executable} -m pip install torch==2.2.0 --no-warn-script-location > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9769f12c-fec0-4003-bbd7-9bbb5dc9eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb68c43-b04e-455a-baa2-40ebc762cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1510af7e-1a83-4d6b-96a1-f75de6940909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3527a6cdc2441caf5ab3e2b353da6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Model='Intel/neural-chat-7b-v3-3'\n",
    "model = AutoModelForCausalLM.from_pretrained(Model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c150e607-9570-479a-99dc-62d08ef50677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ub0d2875c9f8623d9937577605680443/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/quantization/_quantize.py:97: UserWarning: BatchNorm folding failed during the prepare process.\n",
      "  warnings.warn(\"BatchNorm folding failed during the prepare process.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex.llm.optimize is doing the weight only quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ub0d2875c9f8623d9937577605680443/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/reference/modules/attentions.py:2017: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (input_shape[-1] > 1 or self.sliding_window is not None) and self.is_causal:\n",
      "/home/ub0d2875c9f8623d9937577605680443/.local/lib/python3.11/site-packages/transformers/modeling_attn_mask_utils.py:137: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "/home/ub0d2875c9f8623d9937577605680443/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/reference/modules/attentions.py:2043: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  else torch.tensor(expanded_attn_mask) + torch.tensor(causal_4d_mask)\n",
      "/home/ub0d2875c9f8623d9937577605680443/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/reference/modules/attentions.py:2043: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  else torch.tensor(expanded_attn_mask) + torch.tensor(causal_4d_mask)\n",
      "/home/ub0d2875c9f8623d9937577605680443/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/reference/fusions/mha_fusion.py:41: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if seq_len is not None and seq_len > self.max_seq_len_cached:\n",
      "/home/ub0d2875c9f8623d9937577605680443/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/cpu/fusions/mha_fusion.py:86: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  seq_info = torch.tensor(\n",
      "/home/ub0d2875c9f8623d9937577605680443/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/cpu/fusions/mha_fusion.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seq_info = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex.llm.optimize has set the optimized or quantization model for model.generate()\n"
     ]
    }
   ],
   "source": [
    "qconfig = ipex.quantization.get_weight_only_quant_qconfig_mapping(\n",
    "    weight_dtype = torch.quint4x2, #torch.qint8\n",
    "    lowp_mode = ipex.quantization.WoqLowpMode.NONE, # FP16, BF16, INT8\n",
    ")\n",
    "checkpoint=None\n",
    "model_ipex=ipex.llm.optimize(model, quantization_config=qconfig, low_precision_checkpoint=checkpoint)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b72e210b-736c-47d4-a598-6bb5faede9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message= \"\"\"\\n\\n You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
    "prompt= \"\\n\\n You are an expert in Kollywood. Can you tell me 5 fun facts about the Tamil Film Industry?\"\n",
    "model_answer_1 = 'None'\n",
    "\n",
    "prompt_tempate = f\"\"\"\n",
    "### System:\n",
    "{system_message}\n",
    "\n",
    "### User:\n",
    "{prompt}\n",
    "\n",
    "### Assistant:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt_tempate, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59edf615-5173-4adf-ac87-3f28ad1e99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here are some interesting tidbits from the world of South Indian cinema (Telugu/Kannada - \"Sandal\" films; Malayali- \"Mallyuplam\"; Marathi – \"Maratheychi Goshta\", but not so much for now) or more specifically on 'Chennaivarmanchis', i.e., The TAMIL FIlm industry popularly known as ‘’kOLLYWOOD” :\n",
      "1.) Ajith Kumasan is one among few actors who has never won any major awards at SIIMAs(South India International Movie Awards), yet he holds multiple Guinness World Records including “Highest number of tickets sold within three hours for first day, First show”. He also owns record for most movie releases by an actor with his film Billa Suruli getting released simultaneously across 204 screens worldwide without prior publicity. His fans call him Thalaiva which means leader implying that they consider themselves under their own leadership when watching movies featuring this star. This shows how strong fan following can be even if official recognition isn't there always.\n",
      "\n",
      "2.) Kamal Haasan was once offered a role opposite Meryl Streep in Out Of Africa directed by David Leans. But due to unavoidable circumstances like political commitments back home, it didn't materialize leaving us all wondering what could\n"
     ]
    }
   ],
   "source": [
    "streamer = TextStreamer(tokenizer,skip_prompt=True)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    tokens = model_ipex.generate(\n",
    "        inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=300,\n",
    "        repetition_penalty=1.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c556cd-08ac-4073-a971-58f2c57b87d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
